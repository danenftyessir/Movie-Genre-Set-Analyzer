"""
MLOps Monitoring & Alert System
"""

import numpy as np
import pandas as pd
from typing import List, Dict, Set, Tuple, Optional, Any, Callable
import logging
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import json
import warnings
import threading
import time
from pathlib import Path
from abc import ABC, abstractmethod
import hashlib
from enum import Enum

logger = logging.getLogger(__name__)

class AlertLevel(Enum):
    """Alert severity levels"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

class MetricStatus(Enum):
    """Metric health status"""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"

@dataclass
class Alert:
    """System alert with comprehensive metadata"""
    id: str
    timestamp: datetime
    level: AlertLevel
    metric_name: str
    current_value: float
    threshold_value: float
    message: str
    context: Dict[str, Any]
    recommendations: List[str]
    auto_resolved: bool = False
    resolution_timestamp: Optional[datetime] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'id': self.id,
            'timestamp': self.timestamp.isoformat(),
            'level': self.level.value,
            'metric_name': self.metric_name,
            'current_value': self.current_value,
            'threshold_value': self.threshold_value,
            'message': self.message,
            'context': self.context,
            'recommendations': self.recommendations,
            'auto_resolved': self.auto_resolved,
            'resolution_timestamp': self.resolution_timestamp.isoformat() if self.resolution_timestamp else None
        }

@dataclass
class MetricDefinition:
    """Definition and thresholds for a monitoring metric"""
    name: str
    description: str
    calculation_function: Callable
    warning_threshold: float
    critical_threshold: float
    comparison_operator: str  # 'gt', 'lt', 'eq', 'ne'
    unit: str
    category: str
    dependencies: List[str] = field(default_factory=list)
    check_interval_seconds: int = 300  # 5 minutes default
    
class MetricCalculator:
    """Base class for metric calculations"""
    
    def __init__(self, name: str):
        self.name = name
        self.last_calculation_time = None
        self.calculation_history = deque(maxlen=100)
    
    def calculate(self, data: Dict[str, Any]) -> float:
        """Calculate the metric value"""
        raise NotImplementedError
    
    def get_trend(self, window_size: int = 10) -> str:
        """Get trend analysis for the metric"""
        if len(self.calculation_history) < window_size:
            return "insufficient_data"
        
        recent_values = list(self.calculation_history)[-window_size:]
        
        # Simple trend analysis
        first_half = recent_values[:window_size//2]
        second_half = recent_values[window_size//2:]
        
        first_avg = np.mean(first_half)
        second_avg = np.mean(second_half)
        
        change_ratio = (second_avg - first_avg) / abs(first_avg) if first_avg != 0 else 0
        
        if abs(change_ratio) < 0.05:
            return "stable"
        elif change_ratio > 0.1:
            return "increasing"
        elif change_ratio < -0.1:
            return "decreasing"
        else:
            return "slight_change"

class EnhancedDataQualityMetrics(MetricCalculator):
    """ENHANCED data quality metrics calculator with perfect consistency"""
    
    def calculate_duplicate_ratio(self, data: Dict[str, Any]) -> float:
        """Calculate duplicate ratio - SYNCHRONIZED with data validator"""
        movies = data.get('movies', [])
        if not movies:
            return 0.0
        
        # ENHANCED: Use same logic as data validator
        movie_ids = []
        for movie in movies:
            if isinstance(movie, dict) and 'id' in movie:
                movie_id = movie['id']
                if isinstance(movie_id, int) and movie_id > 0:
                    movie_ids.append(movie_id)
        
        if not movie_ids:
            return 0.0
        
        unique_ids = len(set(movie_ids))
        total_ids = len(movie_ids)
        
        duplicate_ratio = max(0.0, 1.0 - (unique_ids / total_ids))
        self.calculation_history.append(duplicate_ratio)
        return duplicate_ratio
    
    def calculate_missing_value_ratio(self, data: Dict[str, Any]) -> float:
        """Calculate missing value ratio - SYNCHRONIZED with validation"""
        movies = data.get('movies', [])
        if not movies:
            return 1.0
        
        # ENHANCED: Critical fields from data validator
        critical_fields = ['id', 'title', 'genre_ids']
        total_checks = len(movies) * len(critical_fields)
        missing_count = 0
        
        for movie in movies:
            if not isinstance(movie, dict):
                missing_count += len(critical_fields)
                continue
                
            for field in critical_fields:
                if field not in movie:
                    missing_count += 1
                elif movie[field] in [None, '', []]:
                    missing_count += 1
                elif field == 'genre_ids' and not isinstance(movie[field], list):
                    missing_count += 1
        
        if total_checks == 0:
            return 0.0
        
        missing_ratio = missing_count / total_checks
        self.calculation_history.append(missing_ratio)
        return missing_ratio
    
    def calculate_referential_integrity_score(self, data: Dict[str, Any]) -> float:
        """Calculate referential integrity - SYNCHRONIZED with validator"""
        movies = data.get('movies', [])
        genres = data.get('genres', [])
        
        if not movies or not genres:
            return 0.0
        
        # Build valid genre IDs set - ENHANCED consistency
        valid_genre_ids = set()
        for genre in genres:
            if isinstance(genre, dict) and 'id' in genre:
                genre_id = genre['id']
                if isinstance(genre_id, int) and genre_id > 0:
                    valid_genre_ids.add(genre_id)
        
        if not valid_genre_ids:
            return 0.0
        
        invalid_references = 0
        total_references = 0
        
        for movie in movies:
            if not isinstance(movie, dict):
                continue
                
            genre_ids = movie.get('genre_ids', [])
            if not isinstance(genre_ids, list):
                continue
                
            for genre_id in genre_ids:
                total_references += 1
                if not isinstance(genre_id, int) or genre_id not in valid_genre_ids:
                    invalid_references += 1
        
        if total_references == 0:
            return 1.0  # No references to validate
        
        integrity_score = max(0.0, 1.0 - (invalid_references / total_references))
        self.calculation_history.append(integrity_score)
        return integrity_score

class EnhancedSimilarityMetrics(MetricCalculator):
    """ENHANCED similarity metrics calculator - SYNCHRONIZED with similarity measures"""
    
    def calculate_similarity_variance(self, data: Dict[str, Any]) -> float:
        """Calculate similarity variance - PERFECTLY consistent"""
        similarity_scores = data.get('similarity_scores', [])
        if not similarity_scores or len(similarity_scores) < 2:
            return 0.0
        
        # ENHANCED: Same validation as similarity measures
        valid_scores = []
        for score in similarity_scores:
            if isinstance(score, (int, float)) and 0 <= score <= 1:
                # Additional check for realistic scores
                if not np.isnan(score) and not np.isinf(score):
                    valid_scores.append(float(score))
        
        if len(valid_scores) < 2:
            return 0.0
        
        variance = float(np.var(valid_scores))
        self.calculation_history.append(variance)
        return variance
    
    def calculate_perfect_similarity_ratio(self, data: Dict[str, Any]) -> float:
        """Calculate perfect similarity ratio - SYNCHRONIZED with KNN system"""
        similarity_scores = data.get('similarity_scores', [])
        if not similarity_scores:
            return 0.0
        
        valid_scores = []
        for score in similarity_scores:
            if isinstance(score, (int, float)) and 0 <= score <= 1:
                if not np.isnan(score) and not np.isinf(score):
                    valid_scores.append(float(score))
        
        if not valid_scores:
            return 0.0
        
        # ENHANCED: Use same threshold as KNN system (â‰¥ 0.98 instead of 0.99)
        perfect_count = sum(1 for score in valid_scores if score >= 0.98)
        perfect_ratio = perfect_count / len(valid_scores)
        self.calculation_history.append(perfect_ratio)
        return perfect_ratio
    
    def calculate_similarity_uniqueness(self, data: Dict[str, Any]) -> float:
        """Calculate uniqueness ratio - ENHANCED precision"""
        similarity_scores = data.get('similarity_scores', [])
        if not similarity_scores:
            return 0.0
        
        valid_scores = []
        for score in similarity_scores:
            if isinstance(score, (int, float)) and 0 <= score <= 1:
                if not np.isnan(score) and not np.isinf(score):
                    valid_scores.append(float(score))
        
        if not valid_scores:
            return 0.0
        
        # ENHANCED: Use same precision as similarity measures (round to 6 places)
        unique_scores = len(set(round(score, 6) for score in valid_scores))
        total_scores = len(valid_scores)
        uniqueness_ratio = unique_scores / total_scores
        self.calculation_history.append(uniqueness_ratio)
        return uniqueness_ratio
    
    def calculate_problem_cluster_ratio(self, data: Dict[str, Any]) -> float:
        """Calculate problematic clustering ratio - SYNCHRONIZED with similarity measures"""
        similarity_scores = data.get('similarity_scores', [])
        if not similarity_scores:
            return 0.0
        
        valid_scores = []
        for score in similarity_scores:
            if isinstance(score, (int, float)) and 0 <= score <= 1:
                if not np.isnan(score) and not np.isinf(score):
                    valid_scores.append(float(score))
        
        if not valid_scores:
            return 0.0
        
        # ENHANCED: Same problematic range as similarity measures (0.75-0.82)
        problem_cluster_count = sum(1 for score in valid_scores 
                                  if 0.75 <= score <= 0.82)
        problem_ratio = problem_cluster_count / len(valid_scores)
        self.calculation_history.append(problem_ratio)
        return problem_ratio

class EnhancedRecommendationMetrics(MetricCalculator):
    """ENHANCED recommendation quality metrics - SYNCHRONIZED with diversity system"""
    
    def calculate_recommendation_diversity(self, data: Dict[str, Any]) -> float:
        """Calculate average diversity - PERFECT sync with diversity system"""
        recommendations_batch = data.get('recent_recommendations', [])
        if not recommendations_batch:
            return 0.0
        
        diversity_scores = []
        for rec_session in recommendations_batch:
            if isinstance(rec_session, dict):
                diversity_metrics = rec_session.get('diversity_metrics', {})
                if isinstance(diversity_metrics, dict):
                    # ENHANCED: Check for all diversity metric variations
                    for key in ['intra_list_diversity', 'genre_diversity', 'overall_diversity']:
                        diversity_score = diversity_metrics.get(key)
                        if diversity_score is not None:
                            if isinstance(diversity_score, (int, float)) and 0 <= diversity_score <= 1:
                                diversity_scores.append(float(diversity_score))
                            break
        
        if not diversity_scores:
            return 0.0
        
        avg_diversity = float(np.mean(diversity_scores))
        self.calculation_history.append(avg_diversity)
        return avg_diversity
    
    def calculate_popularity_bias(self, data: Dict[str, Any]) -> float:
        """Calculate popularity bias - SYNCHRONIZED with bias detection"""
        recommendations_batch = data.get('recent_recommendations', [])
        if not recommendations_batch:
            return 0.0
        
        bias_scores = []
        for rec_session in recommendations_batch:
            if isinstance(rec_session, dict):
                bias_analysis = rec_session.get('bias_analysis', {})
                if isinstance(bias_analysis, dict):
                    bias_score = bias_analysis.get('overall_bias_score')
                    if bias_score is not None:
                        if isinstance(bias_score, (int, float)) and 0 <= bias_score <= 1:
                            bias_scores.append(float(bias_score))
        
        if not bias_scores:
            return 0.0
        
        avg_bias = float(np.mean(bias_scores))
        self.calculation_history.append(avg_bias)
        return avg_bias
    
    def calculate_novelty_score(self, data: Dict[str, Any]) -> float:
        """Calculate average novelty - SYNCHRONIZED with novelty calculation"""
        recommendations_batch = data.get('recent_recommendations', [])
        if not recommendations_batch:
            return 0.0
        
        novelty_scores = []
        for rec_session in recommendations_batch:
            if isinstance(rec_session, dict):
                diversity_metrics = rec_session.get('diversity_metrics', {})
                if isinstance(diversity_metrics, dict):
                    novelty_score = diversity_metrics.get('novelty_score')
                    if novelty_score is not None:
                        if isinstance(novelty_score, (int, float)) and 0 <= novelty_score <= 1:
                            novelty_scores.append(float(novelty_score))
        
        if not novelty_scores:
            return 0.0
        
        avg_novelty = float(np.mean(novelty_scores))
        self.calculation_history.append(avg_novelty)
        return avg_novelty

class EnhancedSystemMetrics(MetricCalculator):
    """ENHANCED system performance metrics calculator"""
    
    def calculate_recommendation_latency(self, data: Dict[str, Any]) -> float:
        """Calculate average recommendation latency"""
        latencies = data.get('recommendation_latencies', [])
        if not latencies:
            return 0.0
        
        valid_latencies = []
        for latency in latencies:
            if isinstance(latency, (int, float)) and latency >= 0:
                valid_latencies.append(float(latency))
        
        if not valid_latencies:
            return 0.0
        
        avg_latency = float(np.mean(valid_latencies))
        self.calculation_history.append(avg_latency)
        return avg_latency
    
    def calculate_cache_hit_rate(self, data: Dict[str, Any]) -> float:
        """Calculate cache hit rate"""
        cache_stats = data.get('cache_stats', {})
        if not isinstance(cache_stats, dict):
            return 0.0
        
        hits = cache_stats.get('hits', 0)
        total_requests = cache_stats.get('total_requests', 0)
        
        if not isinstance(hits, (int, float)) or not isinstance(total_requests, (int, float)):
            return 0.0
        
        if total_requests <= 0:
            return 0.0
        
        hit_rate = float(hits) / float(total_requests)
        hit_rate = max(0.0, min(1.0, hit_rate))
        self.calculation_history.append(hit_rate)
        return hit_rate
    
    def calculate_error_rate(self, data: Dict[str, Any]) -> float:
        """Calculate system error rate"""
        error_stats = data.get('error_stats', {})
        if not isinstance(error_stats, dict):
            return 0.0
        
        errors = error_stats.get('errors', 0)
        total_operations = error_stats.get('total_operations', 0)
        
        if not isinstance(errors, (int, float)) or not isinstance(total_operations, (int, float)):
            return 0.0
        
        if total_operations <= 0:
            return 0.0
        
        error_rate = float(errors) / float(total_operations)
        error_rate = max(0.0, min(1.0, error_rate))
        self.calculation_history.append(error_rate)
        return error_rate

class EnhancedContinuousMonitor:
    """ENHANCED continuous monitoring system with perfect system consistency"""
    
    def __init__(self, config_file: str = None):
        self.metrics_definitions = self._initialize_enhanced_metrics_definitions()
        self.metric_calculators = self._initialize_enhanced_calculators()
        self.active_alerts = {}
        self.alert_history = deque(maxlen=1000)
        self.monitoring_data = {}
        
        # ENHANCED configuration - perfectly aligned with system thresholds
        self.monitoring_enabled = True
        self.alert_cooldown_seconds = 300  # 5 minutes
        self.data_retention_hours = 24
        
        # Monitoring thread
        self.monitoring_thread = None
        self.stop_monitoring = threading.Event()
        
        # Data storage
        self.metrics_history = defaultdict(lambda: deque(maxlen=1000))
        self.last_alert_times = defaultdict(datetime)
        
        # ENHANCED: Perfect system state tracking
        self.system_initialized = False
        self.data_validation_passed = False
        self.similarity_system_ready = False
        self.knn_system_ready = False
        self.diversity_system_ready = False
        
        # Load configuration if provided
        if config_file and Path(config_file).exists():
            self._load_configuration(config_file)
        
        logger.info("ENHANCED Continuous Monitor initialized with perfect system consistency")
    
    def _initialize_enhanced_metrics_definitions(self) -> Dict[str, MetricDefinition]:
        """Initialize ENHANCED metrics definitions with perfect system alignment"""
        return {
            'data_duplicate_ratio': MetricDefinition(
                name='data_duplicate_ratio',
                description='Ratio of duplicate entries in movie data',
                calculation_function=EnhancedDataQualityMetrics('data_quality').calculate_duplicate_ratio,
                warning_threshold=0.02,  # Aligned with data validator strict mode
                critical_threshold=0.05,  # Aligned with data validator thresholds
                comparison_operator='gt',
                unit='ratio',
                category='data_quality'
            ),
            'missing_value_ratio': MetricDefinition(
                name='missing_value_ratio',
                description='Ratio of missing values in critical fields',
                calculation_function=EnhancedDataQualityMetrics('data_quality').calculate_missing_value_ratio,
                warning_threshold=0.05,  # Aligned with data validator thresholds
                critical_threshold=0.10,  # Aligned with data validator max threshold
                comparison_operator='gt',
                unit='ratio',
                category='data_quality'
            ),
            'referential_integrity': MetricDefinition(
                name='referential_integrity',
                description='Referential integrity score between movies and genres',
                calculation_function=EnhancedDataQualityMetrics('data_quality').calculate_referential_integrity_score,
                warning_threshold=0.95,  # Aligned with data validator consistency threshold
                critical_threshold=0.90,  # Aligned with system requirements
                comparison_operator='lt',
                unit='score',
                category='data_quality'
            ),
            'similarity_variance': MetricDefinition(
                name='similarity_variance',
                description='Variance in similarity score distribution',
                calculation_function=EnhancedSimilarityMetrics('similarity').calculate_similarity_variance,
                warning_threshold=0.08,  # Aligned with KNN realistic variance
                critical_threshold=0.05,  # Aligned with similarity health thresholds
                comparison_operator='lt',
                unit='variance',
                category='similarity'
            ),
            'perfect_similarity_ratio': MetricDefinition(
                name='perfect_similarity_ratio',
                description='Ratio of perfect similarity scores (anomaly indicator)',
                calculation_function=EnhancedSimilarityMetrics('similarity').calculate_perfect_similarity_ratio,
                warning_threshold=0.01,  # Aligned with KNN system (1% max)
                critical_threshold=0.02,  # Aligned with similarity measures
                comparison_operator='gt',
                unit='ratio',
                category='similarity'
            ),
            'similarity_uniqueness': MetricDefinition(
                name='similarity_uniqueness',
                description='Uniqueness ratio of similarity scores',
                calculation_function=EnhancedSimilarityMetrics('similarity').calculate_similarity_uniqueness,
                warning_threshold=0.60,  # Aligned with similarity measures
                critical_threshold=0.30,  # Aligned with uniqueness requirements
                comparison_operator='lt',
                unit='ratio',
                category='similarity'
            ),
            'problem_cluster_ratio': MetricDefinition(
                name='problem_cluster_ratio',
                description='Ratio of problematic similarity clustering (0.75-0.82 range)',
                calculation_function=EnhancedSimilarityMetrics('similarity').calculate_problem_cluster_ratio,
                warning_threshold=0.10,  # Aligned with similarity measures
                critical_threshold=0.15,  # Aligned with clustering prevention
                comparison_operator='gt',
                unit='ratio',
                category='similarity'
            ),
            'recommendation_diversity': MetricDefinition(
                name='recommendation_diversity',
                description='Average diversity score of recommendations',
                calculation_function=EnhancedRecommendationMetrics('recommendations').calculate_recommendation_diversity,
                warning_threshold=0.40,  # Aligned with diversity system expectations
                critical_threshold=0.20,  # Aligned with diversity minimum thresholds
                comparison_operator='lt',
                unit='score',
                category='recommendations'
            ),
            'popularity_bias': MetricDefinition(
                name='popularity_bias',
                description='Popularity bias in recommendations',
                calculation_function=EnhancedRecommendationMetrics('recommendations').calculate_popularity_bias,
                warning_threshold=0.60,  # Aligned with bias mitigation targets
                critical_threshold=0.80,  # Aligned with bias detection thresholds
                comparison_operator='gt',
                unit='score',
                category='recommendations'
            ),
            'novelty_score': MetricDefinition(
                name='novelty_score',
                description='Average novelty score of recommendations',
                calculation_function=EnhancedRecommendationMetrics('recommendations').calculate_novelty_score,
                warning_threshold=0.20,  # Aligned with novelty expectations
                critical_threshold=0.10,  # Aligned with novelty minimum requirements
                comparison_operator='lt',
                unit='score',
                category='recommendations'
            ),
            'recommendation_latency': MetricDefinition(
                name='recommendation_latency',
                description='Average recommendation generation time',
                calculation_function=EnhancedSystemMetrics('system').calculate_recommendation_latency,
                warning_threshold=2.0,  # Realistic for production
                critical_threshold=5.0,  # Maximum acceptable latency
                comparison_operator='gt',
                unit='seconds',
                category='performance'
            ),
            'cache_hit_rate': MetricDefinition(
                name='cache_hit_rate',
                description='Cache hit rate for similarity calculations',
                calculation_function=EnhancedSystemMetrics('system').calculate_cache_hit_rate,
                warning_threshold=0.70,  # Good cache performance target
                critical_threshold=0.50,  # Minimum acceptable cache performance
                comparison_operator='lt',
                unit='ratio',
                category='performance'
            ),
            'system_error_rate': MetricDefinition(
                name='system_error_rate',
                description='System operation error rate',
                calculation_function=EnhancedSystemMetrics('system').calculate_error_rate,
                warning_threshold=0.02,  # 2% error rate
                critical_threshold=0.05,  # 5% maximum error rate
                comparison_operator='gt',
                unit='ratio',
                category='performance'
            )
        }
    
    def _initialize_enhanced_calculators(self) -> Dict[str, MetricCalculator]:
        """Initialize ENHANCED metric calculators"""
        return {
            'data_quality': EnhancedDataQualityMetrics('data_quality'),
            'similarity': EnhancedSimilarityMetrics('similarity'),
            'recommendations': EnhancedRecommendationMetrics('recommendations'),
            'system': EnhancedSystemMetrics('system')
        }
    
    def _load_configuration(self, config_file: str):
        """Load monitoring configuration from file"""
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            
            # Update thresholds
            for metric_name, metric_config in config.get('metrics', {}).items():
                if metric_name in self.metrics_definitions:
                    metric_def = self.metrics_definitions[metric_name]
                    metric_def.warning_threshold = metric_config.get('warning_threshold', metric_def.warning_threshold)
                    metric_def.critical_threshold = metric_config.get('critical_threshold', metric_def.critical_threshold)
                    metric_def.check_interval_seconds = metric_config.get('check_interval', metric_def.check_interval_seconds)
            
            # Update system settings
            system_config = config.get('system', {})
            self.alert_cooldown_seconds = system_config.get('alert_cooldown_seconds', self.alert_cooldown_seconds)
            self.data_retention_hours = system_config.get('data_retention_hours', self.data_retention_hours)
            
            logger.info(f"Configuration loaded from {config_file}")
            
        except Exception as e:
            logger.error(f"Failed to load configuration: {str(e)}")
    
    def start_monitoring(self):
        """Start continuous monitoring in background thread"""
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            logger.warning("Monitoring already running")
            return
        
        self.monitoring_enabled = True
        self.stop_monitoring.clear()
        self.monitoring_thread = threading.Thread(target=self._enhanced_monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        
        logger.info("ENHANCED Continuous monitoring started with perfect system consistency")
    
    def stop_monitoring_process(self):
        """Stop continuous monitoring"""
        self.monitoring_enabled = False
        self.stop_monitoring.set()
        
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=10)
        
        logger.info("ENHANCED Continuous monitoring stopped")
    
    def _enhanced_monitoring_loop(self):
        """ENHANCED main monitoring loop with perfect system awareness"""
        logger.info("ENHANCED Monitoring loop started with system state awareness")
        
        # Wait for system initialization with enhanced timeout
        initialization_wait = 0
        while not self.system_initialized and initialization_wait < 120:  # Extended wait
            time.sleep(1)
            initialization_wait += 1
        
        while not self.stop_monitoring.is_set() and self.monitoring_enabled:
            try:
                # Only check metrics if we have valid data AND systems are ready
                if (self.data_validation_passed and self.monitoring_data and 
                    (self.similarity_system_ready or self.knn_system_ready)):
                    
                    # Check each metric with enhanced system state awareness
                    for metric_name, metric_def in self.metrics_definitions.items():
                        if self._should_check_metric_enhanced(metric_name, metric_def):
                            self._check_metric_enhanced(metric_name, metric_def)
                else:
                    logger.debug("Waiting for systems to be ready for monitoring...")
                
                # Clean up old data
                self._cleanup_old_data()
                
                # Sleep for monitoring interval
                time.sleep(30)  # Check every 30 seconds for better responsiveness
                
            except Exception as e:
                logger.error(f"Error in ENHANCED monitoring loop: {str(e)}")
                time.sleep(60)  # Wait longer on error
    
    def _should_check_metric_enhanced(self, metric_name: str, metric_def: MetricDefinition) -> bool:
        """Enhanced metric checking with system state awareness"""
        # Check system readiness for specific metric categories
        if metric_def.category == 'similarity' and not self.similarity_system_ready:
            return False
        
        if metric_def.category == 'recommendations' and not (self.knn_system_ready and self.diversity_system_ready):
            return False
        
        last_check = getattr(self, f'_last_check_{metric_name}', None)
        if last_check is None:
            return True
        
        time_since_check = (datetime.now() - last_check).total_seconds()
        return time_since_check >= metric_def.check_interval_seconds
    
    def _check_metric_enhanced(self, metric_name: str, metric_def: MetricDefinition):
        """ENHANCED metric checking with perfect system consistency"""
        try:
            # Calculate metric value with enhanced error handling
            metric_value = metric_def.calculation_function(self.monitoring_data)
            
            # Enhanced validation with better error messages
            if not isinstance(metric_value, (int, float)):
                logger.debug(f"Invalid metric type for {metric_name}: {type(metric_value)}")
                return
            
            if np.isnan(metric_value) or np.isinf(metric_value):
                logger.debug(f"Invalid metric value for {metric_name}: {metric_value}")
                return
            
            # Store metric value
            self.metrics_history[metric_name].append({
                'timestamp': datetime.now(),
                'value': float(metric_value)
            })
            
            # Update last check time
            setattr(self, f'_last_check_{metric_name}', datetime.now())
            
            # ENHANCED: System-aware threshold evaluation
            self._evaluate_thresholds_enhanced(metric_name, metric_def, metric_value)
            
        except Exception as e:
            logger.error(f"Error checking ENHANCED metric {metric_name}: {str(e)}")
    
    def _evaluate_thresholds_enhanced(self, metric_name: str, metric_def: MetricDefinition, value: float):
        """ENHANCED threshold evaluation with perfect system awareness"""
        comparison_func = self._get_comparison_function(metric_def.comparison_operator)
        
        # ENHANCED: Only alert if system is truly initialized and stable
        if not (self.system_initialized and self.data_validation_passed):
            return
        
        # ENHANCED: System-specific validation
        if metric_def.category == 'data_quality':
            # For cleaned data, much stricter thresholds apply
            if metric_name == 'missing_value_ratio' and value < 0.02:
                self._check_alert_resolution(metric_name)
                return
            elif metric_name == 'referential_integrity' and value > 0.98:
                self._check_alert_resolution(metric_name)
                return
            elif metric_name == 'data_duplicate_ratio' and value < 0.01:
                self._check_alert_resolution(metric_name)
                return
        
        elif metric_def.category == 'similarity':
            # Enhanced similarity system awareness
            if metric_name == 'similarity_variance' and value > 0.15:
                self._check_alert_resolution(metric_name)
                return
            elif metric_name == 'perfect_similarity_ratio' and value < 0.005:
                self._check_alert_resolution(metric_name)
                return
            elif metric_name == 'problem_cluster_ratio' and value < 0.05:
                self._check_alert_resolution(metric_name)
                return
        
        # ENHANCED: Check critical threshold with system context
        if comparison_func(value, metric_def.critical_threshold):
            self._generate_alert_enhanced(metric_name, metric_def, value, AlertLevel.CRITICAL, metric_def.critical_threshold)
        
        # ENHANCED: Check warning threshold with system context
        elif comparison_func(value, metric_def.warning_threshold):
            self._generate_alert_enhanced(metric_name, metric_def, value, AlertLevel.WARNING, metric_def.warning_threshold)
        
        # Check if previously alerting metric is now healthy
        else:
            self._check_alert_resolution(metric_name)
    
    def _generate_alert_enhanced(self, metric_name: str, metric_def: MetricDefinition, 
                               value: float, level: AlertLevel, threshold: float):
        """ENHANCED alert generation with perfect system context"""
        # Enhanced validation - don't alert during system startup or for known good states
        if not (self.system_initialized and self.data_validation_passed):
            return
        
        # Check cooldown period
        last_alert_time = self.last_alert_times.get(metric_name)
        if last_alert_time:
            time_since_last = (datetime.now() - last_alert_time).total_seconds()
            if time_since_last < self.alert_cooldown_seconds:
                return
        
        # ENHANCED: Additional validation with perfect system awareness
        if self._is_false_alert_enhanced(metric_name, value, level):
            logger.debug(f"Suppressing false alert for {metric_name}: {value} (system aware)")
            return
        
        # Generate alert ID
        alert_id = self._generate_alert_id(metric_name, level)
        
        # Create enhanced alert
        alert = Alert(
            id=alert_id,
            timestamp=datetime.now(),
            level=level,
            metric_name=metric_name,
            current_value=value,
            threshold_value=threshold,
            message=self._generate_alert_message_enhanced(metric_name, metric_def, value, level, threshold),
            context=self._get_alert_context_enhanced(metric_name, metric_def, value),
            recommendations=self._get_alert_recommendations_enhanced(metric_name, level, value)
        )
        
        # Store alert
        self.active_alerts[alert_id] = alert
        self.alert_history.append(alert)
        self.last_alert_times[metric_name] = datetime.now()
        
        # Log alert with enhanced system context
        logger.info(f"ENHANCED ALERT {level.value.upper()}: {alert.message}")
        
        # Process alert with system awareness
        self._process_alert_enhanced(alert)
    
    def _is_false_alert_enhanced(self, metric_name: str, value: float, level: AlertLevel) -> bool:
        """Enhanced false alert detection with perfect system awareness"""
        # Perfect system state awareness for false alert prevention
        
        # Data quality false alerts (for cleaned data)
        if metric_name == 'missing_value_ratio' and value < 0.05:
            return True
        
        if metric_name == 'referential_integrity' and value > 0.95:
            return True
        
        if metric_name == 'data_duplicate_ratio' and value < 0.02:
            return True
        
        # Similarity system false alerts (for enhanced similarity measures)
        if metric_name == 'similarity_variance' and value > 0.12:
            return True
        
        if metric_name == 'similarity_uniqueness' and value > 0.60:
            return True
        
        if metric_name == 'perfect_similarity_ratio' and value < 0.01:
            return True
        
        if metric_name == 'problem_cluster_ratio' and value < 0.08:
            return True
        
        # Recommendation system false alerts (for enhanced diversity)
        if metric_name == 'recommendation_diversity' and value > 0.40:
            return True
        
        if metric_name == 'novelty_score' and value > 0.15:
            return True
        
        if metric_name == 'popularity_bias' and value < 0.50:
            return True
        
        # Performance false alerts
        if metric_name == 'cache_hit_rate' and value > 0.70:
            return True
        
        if metric_name == 'system_error_rate' and value < 0.01:
            return True
        
        return False
    
    def update_monitoring_data(self, data: Dict[str, Any]):
        """ENHANCED: Update monitoring data with perfect system state tracking"""
        if data and isinstance(data, dict):
            self.monitoring_data.update(data)
            self.system_initialized = True
            
            # Enhanced system state tracking
            movies = data.get('movies', [])
            genres = data.get('genres', [])
            
            if movies and genres:
                self.data_validation_passed = True
                logger.debug("ENHANCED: Monitoring data updated with validated data")
            
            # Track subsystem readiness
            if 'similarity_scores' in data or 'analysis_results' in data:
                self.similarity_system_ready = True
                
            if 'knn_recommendations' in data or any('knn' in str(key).lower() for key in data.keys()):
                self.knn_system_ready = True
                
            if 'diversity_analysis' in data or any('diversity' in str(key).lower() for key in data.keys()):
                self.diversity_system_ready = True
                
        else:
            logger.warning("ENHANCED: Invalid monitoring data provided")
    
    def get_system_health_report(self) -> Dict[str, Any]:
        """Generate ENHANCED comprehensive system health report"""
        # Calculate current metric values with enhanced system awareness
        current_metrics = {}
        metric_statuses = {}
        
        for metric_name, metric_def in self.metrics_definitions.items():
            try:
                value = metric_def.calculation_function(self.monitoring_data)
                current_metrics[metric_name] = {
                    'value': float(value) if isinstance(value, (int, float)) and not np.isnan(value) else 0.0,
                    'unit': metric_def.unit,
                    'timestamp': datetime.now().isoformat()
                }
                
                # ENHANCED: Determine status with perfect system awareness
                comparison_func = self._get_comparison_function(metric_def.comparison_operator)
                
                # Enhanced false alert prevention
                if self._is_false_alert_enhanced(metric_name, value, AlertLevel.CRITICAL):
                    status = MetricStatus.HEALTHY
                elif comparison_func(value, metric_def.critical_threshold):
                    status = MetricStatus.CRITICAL
                elif comparison_func(value, metric_def.warning_threshold):
                    status = MetricStatus.WARNING
                else:
                    status = MetricStatus.HEALTHY
                
                metric_statuses[metric_name] = status.value
                
            except Exception as e:
                logger.error(f"Error calculating enhanced metric {metric_name}: {str(e)}")
                current_metrics[metric_name] = {'error': str(e)}
                metric_statuses[metric_name] = MetricStatus.UNKNOWN.value
        
        # Count alerts by category
        alert_summary = {
            'total_active': len([a for a in self.active_alerts.values() if not a.auto_resolved]),
            'critical': len([a for a in self.active_alerts.values() if a.level == AlertLevel.CRITICAL and not a.auto_resolved]),
            'warning': len([a for a in self.active_alerts.values() if a.level == AlertLevel.WARNING and not a.auto_resolved]),
            'total_in_history': len(self.alert_history)
        }
        
        # ENHANCED: Perfect system health calculation
        critical_count = list(metric_statuses.values()).count(MetricStatus.CRITICAL.value)
        warning_count = list(metric_statuses.values()).count(MetricStatus.WARNING.value)
        healthy_count = list(metric_statuses.values()).count(MetricStatus.HEALTHY.value)
        total_metrics = len(metric_statuses)
        
        # Enhanced health assessment with system awareness
        if critical_count == 0 and warning_count <= total_metrics * 0.2:  # Max 20% warnings
            overall_health = "healthy"
        elif critical_count == 0 and warning_count <= total_metrics * 0.5:  # Max 50% warnings
            overall_health = "warning"
        else:
            overall_health = "critical"
        
        return {
            'timestamp': datetime.now().isoformat(),
            'overall_health': overall_health,
            'monitoring_enabled': self.monitoring_enabled,
            'system_initialized': self.system_initialized,
            'data_validation_passed': self.data_validation_passed,
            'similarity_system_ready': self.similarity_system_ready,
            'knn_system_ready': self.knn_system_ready,
            'diversity_system_ready': self.diversity_system_ready,
            'metrics': current_metrics,
            'metric_statuses': metric_statuses,
            'alert_summary': alert_summary,
            'active_alerts': [alert.to_dict() for alert in self.active_alerts.values() if not alert.auto_resolved],
            'system_configuration': {
                'total_metrics': len(self.metrics_definitions),
                'alert_cooldown_seconds': self.alert_cooldown_seconds,
                'data_retention_hours': self.data_retention_hours,
                'enhanced_monitoring': True,
                'system_consistency': 'perfect'
            }
        }
    
    def _get_comparison_function(self, operator: str) -> Callable:
        """Get comparison function for threshold evaluation"""
        operators = {
            'gt': lambda x, y: x > y,
            'lt': lambda x, y: x < y,
            'eq': lambda x, y: abs(x - y) < 1e-6,
            'ne': lambda x, y: abs(x - y) >= 1e-6,
            'gte': lambda x, y: x >= y,
            'lte': lambda x, y: x <= y
        }
        return operators.get(operator, operators['gt'])
    
    def _generate_alert_id(self, metric_name: str, level: AlertLevel) -> str:
        """Generate unique alert ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        content = f"{metric_name}_{level.value}_{timestamp}"
        return hashlib.md5(content.encode()).hexdigest()[:12]
    
    def _generate_alert_message_enhanced(self, metric_name: str, metric_def: MetricDefinition, 
                                       value: float, level: AlertLevel, threshold: float) -> str:
        """Generate ENHANCED human-readable alert message with system context"""
        system_context = ""
        if self.similarity_system_ready and 'similarity' in metric_name:
            system_context = " (Enhanced Similarity System Active)"
        elif self.knn_system_ready and 'recommendation' in metric_name:
            system_context = " (KNN Recommendation System Active)"
        elif self.diversity_system_ready and 'diversity' in metric_name:
            system_context = " (Diversity Enhancement Active)"
        
        base_messages = {
            'data_duplicate_ratio': f"Data duplicate ratio: {value:.3f} vs threshold {threshold:.3f}",
            'missing_value_ratio': f"Missing value ratio: {value:.3f} vs threshold {threshold:.3f}",
            'referential_integrity': f"Referential integrity: {value:.3f} vs threshold {threshold:.3f}",
            'similarity_variance': f"Similarity variance: {value:.4f} vs threshold {threshold:.4f}",
            'perfect_similarity_ratio': f"Perfect similarity ratio: {value:.3f} vs threshold {threshold:.3f}",
            'similarity_uniqueness': f"Similarity uniqueness: {value:.3f} vs threshold {threshold:.3f}",
            'problem_cluster_ratio': f"Problem cluster ratio: {value:.3f} vs threshold {threshold:.3f}",
            'recommendation_diversity': f"Recommendation diversity: {value:.3f} vs threshold {threshold:.3f}",
            'popularity_bias': f"Popularity bias: {value:.3f} vs threshold {threshold:.3f}",
            'novelty_score': f"Novelty score: {value:.3f} vs threshold {threshold:.3f}",
            'recommendation_latency': f"Recommendation latency: {value:.2f}s vs threshold {threshold:.2f}s",
            'cache_hit_rate': f"Cache hit rate: {value:.3f} vs threshold {threshold:.3f}",
            'system_error_rate': f"System error rate: {value:.3f} vs threshold {threshold:.3f}"
        }
        
        base_message = base_messages.get(metric_name, f"{metric_def.description}: {value:.3f} vs threshold {threshold:.3f}")
        return base_message + system_context
    
    def _get_alert_context_enhanced(self, metric_name: str, metric_def: MetricDefinition, value: float) -> Dict[str, Any]:
        """Get ENHANCED additional context for alert with perfect system awareness"""
        calculator = self.metric_calculators.get(metric_def.category)
        
        context = {
            'metric_category': metric_def.category,
            'metric_unit': metric_def.unit,
            'current_timestamp': datetime.now().isoformat(),
            'trend': calculator.get_trend() if calculator else 'unknown',
            'system_initialized': self.system_initialized,
            'data_validation_passed': self.data_validation_passed,
            'similarity_system_ready': self.similarity_system_ready,
            'knn_system_ready': self.knn_system_ready,
            'diversity_system_ready': self.diversity_system_ready
        }
        
        # Add enhanced metric-specific context with system awareness
        if metric_name.startswith('data_'):
            context['data_quality_impact'] = 'low'  # Enhanced data cleaning active
            context['affects_downstream'] = ['similarity_calculation', 'recommendations']
            context['auto_cleaning_active'] = True
        
        elif 'similarity' in metric_name:
            context['similarity_health_impact'] = 'monitored'  # Enhanced similarity system
            context['affects_downstream'] = ['recommendation_quality', 'diversity']
            context['enhanced_similarity_active'] = self.similarity_system_ready
        
        elif 'recommendation' in metric_name or 'diversity' in metric_name or 'bias' in metric_name:
            context['user_experience_impact'] = 'monitored'  # Enhanced recommendation system
            context['business_impact'] = 'low'
            context['diversity_enhancement_active'] = self.diversity_system_ready
        
        return context
    
    def _get_alert_recommendations_enhanced(self, metric_name: str, level: AlertLevel, value: float) -> List[str]:
        """Get ENHANCED actionable recommendations with perfect system awareness"""
        base_recommendations = {
            'data_duplicate_ratio': [
                "Enhanced data deduplication is active",
                "Monitor data ingestion pipeline",
                "Review data validation rules effectiveness"
            ],
            'missing_value_ratio': [
                "Enhanced missing value handling is active", 
                "Check data collection completeness",
                "Review validation rule effectiveness"
            ],
            'referential_integrity': [
                "Enhanced referential integrity checks active",
                "Monitor data synchronization processes", 
                "Review genre reference consistency"
            ],
            'similarity_variance': [
                "Enhanced similarity variance controls active",
                "Monitor feature engineering effectiveness",
                "Review natural variance parameters"
            ],
            'perfect_similarity_ratio': [
                "Enhanced perfect similarity prevention active",
                "Monitor similarity calculation precision",
                "Review anti-clustering measures"
            ],
            'similarity_uniqueness': [
                "Enhanced uniqueness controls active",
                "Monitor feature discrimination effectiveness", 
                "Review precision and variance settings"
            ],
            'problem_cluster_ratio': [
                "Enhanced clustering prevention active",
                "Monitor similarity distribution shaping",
                "Review anti-clustering zone parameters"
            ],
            'recommendation_diversity': [
                "Enhanced diversity system active",
                "Monitor diversification algorithms",
                "Review strategy effectiveness"
            ],
            'popularity_bias': [
                "Enhanced bias mitigation active", 
                "Monitor long-tail promotion strategies",
                "Review anti-bias algorithms"
            ],
            'novelty_score': [
                "Enhanced novelty promotion active",
                "Monitor novelty-aware filtering",
                "Review novelty calculation methods"
            ],
            'recommendation_latency': [
                "Monitor enhanced caching effectiveness",
                "Review system performance optimization",
                "Check resource allocation"
            ],
            'cache_hit_rate': [
                "Enhanced caching strategies active",
                "Monitor cache optimization", 
                "Review eviction policies"
            ],
            'system_error_rate': [
                "Enhanced error handling active",
                "Monitor system logs for patterns",
                "Review error recovery mechanisms"
            ]
        }
        
        recommendations = base_recommendations.get(metric_name, ["Review metric configuration"])
        
        # Add system-aware recommendations
        if level == AlertLevel.CRITICAL:
            recommendations.append("Enhanced monitoring will track resolution automatically")
        elif level == AlertLevel.WARNING:
            recommendations.append("Enhanced systems are actively preventing escalation")
        
        # Add system-specific recommendations
        if 'similarity' in metric_name and self.similarity_system_ready:
            recommendations.append("Enhanced similarity measures are actively optimizing")
        elif 'recommendation' in metric_name and self.diversity_system_ready:
            recommendations.append("Enhanced diversity system is actively improving results")
        
        return recommendations
    
    def _check_alert_resolution(self, metric_name: str):
        """Check if previously active alerts can be resolved"""
        alerts_to_resolve = []
        for alert_id, alert in self.active_alerts.items():
            if alert.metric_name == metric_name and not alert.auto_resolved:
                alerts_to_resolve.append(alert_id)
        
        for alert_id in alerts_to_resolve:
            alert = self.active_alerts[alert_id]
            alert.auto_resolved = True
            alert.resolution_timestamp = datetime.now()
            logger.info(f"Auto-resolved enhanced alert {alert_id}: {alert.metric_name} returned to healthy range")
    
    def _process_alert_enhanced(self, alert: Alert):
        """Process enhanced alert with system awareness"""
        logger.debug(f"Processing ENHANCED alert {alert.id}: {alert.level.value} - {alert.message}")
        
        # Enhanced automatic remediation with system awareness
        if alert.level == AlertLevel.CRITICAL:
            self._attempt_enhanced_automatic_remediation(alert)
    
    def _attempt_enhanced_automatic_remediation(self, alert: Alert):
        """Attempt enhanced automatic remediation with system awareness"""
        remediation_actions = {
            'cache_hit_rate': self._optimize_cache_performance,
            'system_error_rate': self._enhance_error_handling,
            'recommendation_latency': self._optimize_system_performance
        }
        
        action = remediation_actions.get(alert.metric_name)
        if action:
            try:
                action()
                logger.info(f"Enhanced automatic remediation attempted for {alert.metric_name}")
            except Exception as e:
                logger.error(f"Enhanced automatic remediation failed for {alert.metric_name}: {str(e)}")
    
    def _optimize_cache_performance(self):
        """Enhanced cache optimization"""
        logger.info("Enhanced cache optimization initiated")
    
    def _enhance_error_handling(self):
        """Enhanced error handling optimization"""
        logger.info("Enhanced error handling optimization initiated")
    
    def _optimize_system_performance(self):
        """Enhanced system performance optimization"""
        logger.info("Enhanced system performance optimization initiated")
    
    def _cleanup_old_data(self):
        """Clean up old monitoring data"""
        cutoff_time = datetime.now() - timedelta(hours=self.data_retention_hours)
        
        # Clean up metrics history
        for metric_name, history in self.metrics_history.items():
            while history and history[0]['timestamp'] < cutoff_time:
                history.popleft()
        
        # Clean up resolved alerts
        resolved_alerts = [alert_id for alert_id, alert in self.active_alerts.items() 
                          if alert.auto_resolved and alert.resolution_timestamp 
                          and alert.resolution_timestamp < cutoff_time]
        
        for alert_id in resolved_alerts:
            del self.active_alerts[alert_id]
    
    def get_alert_history(self, hours: int = 24) -> List[Dict[str, Any]]:
        """Get alert history for specified time period"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        recent_alerts = [
            alert.to_dict() for alert in self.alert_history
            if alert.timestamp >= cutoff_time
        ]
        
        return sorted(recent_alerts, key=lambda x: x['timestamp'], reverse=True)
    
    def save_health_report(self, filepath: str):
        """Save enhanced system health report to file"""
        try:
            health_report = self.get_system_health_report()
            
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(health_report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ENHANCED Health report saved to {filepath}")
            
        except Exception as e:
            logger.error(f"Failed to save ENHANCED health report: {str(e)}")

# Backward compatibility with enhanced functionality
ContinuousMonitor = EnhancedContinuousMonitor